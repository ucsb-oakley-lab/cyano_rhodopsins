{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c26a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need ancseq kernel\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#Define paths for current project\n",
    "# --- Centralized paths ---\n",
    "ROOT = Path(\"..\")\n",
    "DATA = ROOT / \"data\"\n",
    "LOGS = ROOT / \"logs\"\n",
    "SCRIPTS = ROOT / \"scripts\"\n",
    "RESULTS = ROOT / \"results\"\n",
    "ALIGN_DIR = RESULTS / \"align\"\n",
    "TREE_DIR = RESULTS / \"trees\"\n",
    "FIGURES = RESULTS / \"figures\"\n",
    "ANCESTORS = RESULTS / \"ancestors\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8712b",
   "metadata": {},
   "source": [
    "**Note:**  \n",
    "For long-running jobs (like `ancseq`), do **not** run them in a Jupyter notebook if you are worried about losing your connection.  \n",
    "Instead, use a terminal multiplexer such as `tmux` or `screen` in a regular terminal:\n",
    "\n",
    "1. Open a terminal.\n",
    "2. Start a tmux session: `tmux`\n",
    "3. Activate your environment and run your command:\n",
    "   ```\n",
    "   conda activate ancseq\n",
    "   ancseq -s ../results/align/combined_plus_hasegawa24_ALN.fasta -m AA -o ../results/ancestors/cph24\n",
    "   ```\n",
    "4. Detach from tmux with `Ctrl+b` then `d`.\n",
    "\n",
    "This ensures your job continues running even if you disconnect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined alignment and ancestor sequences written to ../data/final_with_ancestors.fasta\n",
      "Aligned -> ../results/align/final_with_ancestors_ALN.fasta\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Paths\n",
    "HITS = ALIGN_DIR / \"pumphits_ALN.fasta\"\n",
    "ANCESTOR_FASTA = ANCESTORS / \"cph24/30_result/ancestral_state_result.fasta\"\n",
    "FINAL = DATA / \"final_with_ancestors.fasta\"\n",
    "\n",
    "# Ancestor node names\n",
    "Ancestors = (\"Node36\", \"Node73\", \"Node37\", \"Node6\",\n",
    "             \"Node87\", \"Node4\", \"Node117\", \"Node38\",\n",
    "             \"Node40\", \"Node44\")\n",
    "\n",
    "#Node 36 is the root in a midpoint rooted tree\n",
    "#Node 73 is ancestor of PR sequences\n",
    "#Node 37 is ancestor of all GR + NaR\n",
    "#Node 6 is ancestor of all CyHR\n",
    "#Node 87 is ancestor of all XeR\n",
    "#Node 4 is ancestor of all YCyR + GCyR + BR\n",
    "#Node 117 is the ancestor of BR\n",
    "#Node 38 is the ancestor of GR\n",
    "#Node 40 and 44 are ancestors within GR Clade\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read original alignment\n",
    "aln_records = list(SeqIO.parse(HITS, \"fasta\"))\n",
    "\n",
    "# Read ancestor sequences\n",
    "ancestor_records = [rec for rec in SeqIO.parse(ANCESTOR_FASTA, \"fasta\") if rec.id in Ancestors]\n",
    "\n",
    "# Concatenate and write to FINAL\n",
    "with open(FINAL, \"w\") as out_handle:\n",
    "    SeqIO.write(aln_records + ancestor_records, out_handle, \"fasta\")\n",
    "\n",
    "print(f\"Combined alignment and ancestor sequences written to {FINAL}\")\n",
    "\n",
    "# Align with MAFFT\n",
    "ALN_FASTA = ALIGN_DIR / \"final_with_ancestors_ALN.fasta\"\n",
    "!mafft --auto --thread -1 --quiet \"{FINAL}\" > \"{ALN_FASTA}\"\n",
    "print(\"Aligned ->\", ALN_FASTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15d8364",
   "metadata": {},
   "source": [
    "#### Repeat using TM-COFFEE Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958624a",
   "metadata": {},
   "source": [
    "### Repeat using tm-coffee alignment \n",
    "For long-running jobs (like `ancseq`), do **not** run them in a Jupyter notebook if you are worried about losing your connection.  \n",
    "Instead, use a terminal multiplexer such as `tmux` or `screen` in a regular terminal:\n",
    "\n",
    "1. Open a terminal.\n",
    "2. Start a tmux session: `tmux`\n",
    "3. Activate your environment and run your command:\n",
    "   ```\n",
    "   conda activate ancseq\n",
    "   ancseq -s ../results/align/tmcoffee/result.fasta_aln -m AA -o ../results/ancestors/cph24_tcoffee\n",
    "   ```\n",
    "4. Detach from tmux with `Ctrl+b` then `d`.\n",
    "\n",
    "This ensures your job continues running even if you disconnect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9a1573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined alignment and ancestor sequences written to ../data/final_with_ancestors_tcoffee.fasta\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Paths\n",
    "HITS = DATA / \"pumphitsM.fasta\"\n",
    "ANCESTOR_FASTA = ANCESTORS / \"cph24_tcoffee/30_result/ancestral_state_result.fasta\"\n",
    "FINAL = DATA / \"final_with_ancestors_tcoffee.fasta\"\n",
    "\n",
    "# Ancestor node names\n",
    "Ancestors = (\"Node36\", \"Node6\", \"Node87\", \"Node5\",\n",
    "             \"Node116\", \"Node45\", \"Node37\", \"Node44\",\n",
    "             \"Node41\", \"Node38\")\n",
    "\n",
    "# Read original alignment\n",
    "aln_records = list(SeqIO.parse(HITS, \"fasta\"))\n",
    "\n",
    "# Read ancestor sequences\n",
    "ancestor_records = [rec for rec in SeqIO.parse(ANCESTOR_FASTA, \"fasta\") if rec.id in Ancestors]\n",
    "\n",
    "# Concatenate and write to FINAL\n",
    "with open(FINAL, \"w\") as out_handle:\n",
    "    SeqIO.write(aln_records + ancestor_records, out_handle, \"fasta\")\n",
    "\n",
    "print(f\"Combined alignment and ancestor sequences written to {FINAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ebe73",
   "metadata": {},
   "source": [
    "#### Visual inspection of alignment leads to discovery of sequences to remove\n",
    "\n",
    "# BRhit__Halobacterium_salinarum__UniRef90_UPI0000110B77\n",
    "# That sequence is identical to one in the alignment, but missing several amino acids, will simply remove\n",
    "\n",
    "# GCyR2hit__Pseudanabaenaceae_cyanobacterium_LEGE_13415__UniRef90_A0A928YZN9\n",
    "# That sequence has another from the same species that is very similar but not truncated\n",
    "\n",
    "# GRhit__Chamaesiphon_sp__UniRef90_UPI0035935AE6\n",
    "# That sequence has others from the same species that are highly similar but not truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d10c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: 'BRhit__Halobacterium_salinarum__UniRef90_UPI0000110B77' (normalized: 'BRhit__Halobacterium_salinarum__UniRef90_UPI0000110B77')\n",
      "Removed: 'GCyR2hit__Pseudanabaenaceae_cyanobacterium_LEGE_13415__UniRef90_A0A928YZN9' (normalized: 'GCyR2hit__Pseudanabaenaceae_cyanobacterium_LEGE_13415__UniRef90_A0A928YZN9')\n",
      "Removed: 'GRhit__Chamaesiphon_sp__UniRef90_UPI0035935AE6' (normalized: 'GRhit__Chamaesiphon_sp__UniRef90_UPI0035935AE6')\n",
      "Filtered FASTA written to ../data/final_with_ancestors_tcoffee_culled.fasta\n",
      "Total sequences removed: 3\n",
      "Total unique sequences retained: 101\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "input_fasta = \"../data/final_with_ancestors_tcoffee.fasta\"\n",
    "output_fasta = \"../data/final_with_ancestors_tcoffee_culled.fasta\"\n",
    "\n",
    "remove_ids = [\n",
    "    \"BRhit__Halobacterium_salinarum__UniRef90_UPI0000110B77\",\n",
    "    \"GCyR2hit__Pseudanabaenaceae_cyanobacterium_LEGE_13415__UniRef90_A0A928YZN9\",\n",
    "    \"GRhit__Chamaesiphon_sp__UniRef90_UPI0035935AE6\"\n",
    "]\n",
    "\n",
    "def normalize_id(s):\n",
    "    return \"\".join(s.strip().strip('\"').strip(\"'\").split())\n",
    "\n",
    "remove_ids_normalized = set(normalize_id(x) for x in remove_ids)\n",
    "\n",
    "records = []\n",
    "removed_count = 0\n",
    "with open(input_fasta) as in_handle:\n",
    "    for record in SeqIO.parse(in_handle, \"fasta\"):\n",
    "        rec_id_norm = normalize_id(record.id)\n",
    "        if rec_id_norm not in remove_ids_normalized:\n",
    "            records.append(record)\n",
    "        else:\n",
    "            print(f\"Removed: {record.id!r} (normalized: {rec_id_norm!r})\")\n",
    "            removed_count += 1\n",
    "\n",
    "with open(output_fasta, \"w\") as out_handle:\n",
    "    SeqIO.write(records, out_handle, \"fasta\")\n",
    "\n",
    "print(f\"Filtered FASTA written to {output_fasta}\")\n",
    "print(f\"Total sequences removed: {removed_count}\")\n",
    "print(f\"Total unique sequences retained: {len(records)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ancseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
